{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d580618a-0ab5-42ce-a86f-8ff3409398f4",
   "metadata": {},
   "source": [
    "# Convert PDF to Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b9e1a-2f01-484a-bf5d-23474189fb15",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8905a6c6-aa69-4797-bd67-effa3c45fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def extract_pdf_pages(input_pdf, output_pdf, page_start=0, page_end=None):\n",
    "    \"\"\"\n",
    "    Extract specific pages from a PDF and save them to a new file.\n",
    "    \n",
    "    Parameters:\n",
    "        input_pdf (str): Path to the input PDF.\n",
    "        output_pdf (str): Path where the new PDF will be saved.\n",
    "        pages (list): List of page numbers to extract (1-based index).\n",
    "        \n",
    "    Example:\n",
    "        extract_pdf_pages(\"input.pdf\", \"output.pdf\", [1, 2, 4])\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Derive page indexes\n",
    "    if page_end is None:\n",
    "        page_end = len(reader.pages)\n",
    "    pages = list(range(page_start, page_end))\n",
    "    \n",
    "    # Convert to 0-based indexing for PyPDF2\n",
    "    for page_num in pages:\n",
    "        idx = page_num - 1\n",
    "        if 0 <= idx < len(reader.pages):\n",
    "            writer.add_page(reader.pages[idx])\n",
    "        else:\n",
    "            print(f\"Warning: Page {page_num} is out of range and will be skipped.\")\n",
    "\n",
    "    # Save the new PDF\n",
    "    with open(output_pdf, \"wb\") as f:\n",
    "        writer.write(f)\n",
    "\n",
    "    print(f\"Extracted {len(pages)} pages and saved to {output_pdf}\")\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def pdf_to_text_pypdf2(input_pdf, output_txt):\n",
    "    \"\"\"\n",
    "    Extracts all text from a PDF and saves it to a text file.\n",
    "\n",
    "    Parameters:\n",
    "        input_pdf (str): Path to the input PDF file.\n",
    "        output_txt (str): Path to save the extracted text.\n",
    "    \n",
    "    Example:\n",
    "        pdf_to_text(\"example.pdf\", \"output.txt\")\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    all_text = []\n",
    "\n",
    "    # Extract text from each page\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        text = page.extract_text() or \"\"  # Handle blank pages gracefully\n",
    "        all_text.append(f\"--- Page {i+1} ---\\n{text}\\n\")\n",
    "\n",
    "    # Write to output file\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(all_text)\n",
    "\n",
    "    print(f\"Extracted text saved to {output_txt}\")\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "# !pip install PyMuPDF markdownify\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "def pdf_to_markdown_pymupdf(pdf_path, markdown_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_html_content = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        # Extract as HTML. 'layout=True' helps with structure.\n",
    "        # You can experiment with other flags for get_text().\n",
    "        html_content = page.get_text(\"text\") # or get_text(\"xhtml\")\n",
    "        full_html_content += html_content\n",
    "        # Add a page break marker (optional, but can be useful for LLM context)\n",
    "        # full_html_content += \"\\n<hr />\\n\" # HTML horizontal rule\n",
    "        full_html_content += f\"\\n --- END OF PAGE ({page_num + 1}) ---\\n\\n\" # HTML horizontal rule\n",
    "\n",
    "    # Clean up common PDF artifacts from HTML before converting to Markdown\n",
    "    # This is a very basic example; you'll likely need more sophisticated cleaning\n",
    "    # full_html_content = full_html_content.replace(\"­\", \"\") # Remove soft hyphens\n",
    "\n",
    "    # markdown_content = md(full_html_content)\n",
    "    markdown_content = full_html_content\n",
    "\n",
    "    # Further cleanup of Markdown (example: remove excessive newlines)\n",
    "    # markdown_content = \"\\n\".join([line for line in markdown_content.splitlines() if line.strip()])\n",
    "\n",
    "    with open(markdown_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "\n",
    "    print(f\"Converted '{pdf_path}' to '{markdown_path}'\")\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "# !pip install pdfplumber tqdm\n",
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pdf_to_text_pdfplumber(input_file_path, output_file_path):\n",
    "    with pdfplumber.open(input_file_path) as pdf, open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for page in tqdm(pdf.pages, desc=\"Extracting text\", unit=\"page\"):\n",
    "            t = page.extract_text()\n",
    "            if t:\n",
    "                f.write(t + '\\n')\n",
    "\n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2787ad-f39c-438b-9144-746572fe4d50",
   "metadata": {},
   "source": [
    "### List pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8b1012-3780-490e-89e3-18535e955ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rules_monopolypedia.pdf',\n",
       " 'rules_fgbradleys.pdf',\n",
       " 'rules_official-game-rules.pdf',\n",
       " 'rules_netsuite.pdf',\n",
       " 'rules_wikibooks.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_pdf_folder = '/home/luisresende/work/projects/monopoly/assets/rules/pdf'\n",
    "rules_markdown_folder = '/home/luisresende/work/projects/monopoly/assets/rules/markdown'\n",
    "\n",
    "files = os.listdir(rules_pdf_folder)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf3b1c-7fc0-4007-9cc8-8a3f7457c229",
   "metadata": {},
   "source": [
    "### Convert PDF to text with `PyPDF2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a5446b-4742-4d77-9ded-36b7c553b12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text saved to /home/luisresende/work/projects/monopoly/assets/rules/markdown/pypdf2/rules_monopolypedia.md\n",
      "Extracted text saved to /home/luisresende/work/projects/monopoly/assets/rules/markdown/pypdf2/rules_fgbradleys.md\n",
      "Extracted text saved to /home/luisresende/work/projects/monopoly/assets/rules/markdown/pypdf2/rules_official-game-rules.md\n",
      "Extracted text saved to /home/luisresende/work/projects/monopoly/assets/rules/markdown/pypdf2/rules_netsuite.md\n",
      "Extracted text saved to /home/luisresende/work/projects/monopoly/assets/rules/markdown/pypdf2/rules_wikibooks.md\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "\n",
    "    input_path = f'{rules_pdf_folder}/{files[i]}'\n",
    "    output_path = f'{rules_markdown_folder}/pypdf2/{files[i].replace(\".pdf\", \".md\")}'\n",
    "    \n",
    "    pdf_to_text_pypdf2(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9ebe7-9bba-4659-a04f-d77ac1e0737d",
   "metadata": {},
   "source": [
    "### Convert PDF to markdown with `PyMuPDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d70ed2-9a8f-445c-9d92-373845eed209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted '/home/luisresende/work/projects/fg-ai/checklist-generation/data/spec-docs/Specifications_small_selected_pages.pdf' to '/home/luisresende/work/projects/fg-ai/checklist-generation/data/spec-docs/Specifications_small_selected_pages.md'\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "\n",
    "    input_path = f'{rules_pdf_folder}/{files[i]}'\n",
    "    output_path = f'{rules_markdown_folder}/pymupdf/{files[i].replace(\".pdf\", \".md\")}'\n",
    "    \n",
    "    pdf_to_markdown_pymupdf(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d0668-b7b7-4929-89c2-285d6dad9a5e",
   "metadata": {},
   "source": [
    "### Convert PDF to text with `pdfplumber`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30837c32-09ca-4d73-a43a-b403dc6b8301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text: 100%|████████████████████████| 72/72 [00:47<00:00,  1.50page/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "\n",
    "    input_path = f'{rules_pdf_folder}/{files[i]}'\n",
    "    output_path = f'{rules_markdown_folder}/pdfplumber/{files[i].replace(\".pdf\", \".md\")}'\n",
    "    \n",
    "    pdf_to_text_pdfplumber(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed279a-92f9-4c66-b2a7-95a1799e017b",
   "metadata": {},
   "source": [
    "### Convert PDF to text with `markitdown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec400da-cfd8-412a-908d-a01d9d4ec596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/microsoft/markitdown\n",
    "# !pip install 'markitdown[pdf, docx, pptx]'\n",
    "# !pip install 'markitdown[pdf]' # pdf plugin only\n",
    "\n",
    "for i in range(len(files)):\n",
    "\n",
    "    input_path = f'{rules_pdf_folder}/{files[i]}'\n",
    "    output_path = f'{rules_markdown_folder}/markitdown/{files[i].replace(\".pdf\", \".md\")}'\n",
    "    \n",
    "    !markitdown {input_path} > {output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e61e4-3920-425f-a369-0e646ab96a75",
   "metadata": {},
   "source": [
    "### Convert PDF to text using `MinerU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7cd1e4-60c6-4ee2-937f-ac63f56f82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 09:39:55.568753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753447195.740332    9773 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753447195.791705    9773 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753447196.101012    9773 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753447196.101112    9773 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753447196.101122    9773 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753447196.101129    9773 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 09:39:56.137112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[32m2025-07-25 09:40:06.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmineru.backend.vlm.predictor\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[33m\u001b[1msglang is not installed. If you are not using sglang, you can ignore this warning.\u001b[0m\n",
      "\u001b[32m2025-07-25 09:40:16.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmineru.backend.pipeline.pipeline_analyze\u001b[0m:\u001b[36mdoc_analyze\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mBatch 1/1: 10 pages/10 pages\u001b[0m\n",
      "\u001b[32m2025-07-25 09:40:16.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmineru.backend.pipeline.model_init\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mDocAnalysis init, this may take some times......\u001b[0m\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  5.60it/s]\n",
      "Fetching 7 files: 100%|███████████████████████████| 7/7 [00:00<00:00, 14.23it/s]\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  7.12it/s]\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "Fetching 1 files: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "\u001b[32m2025-07-25 09:40:30.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmineru.backend.pipeline.model_init\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mDocAnalysis init done!\u001b[0m\n",
      "\u001b[32m2025-07-25 09:40:30.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmineru.backend.pipeline.pipeline_analyze\u001b[0m:\u001b[36mcustom_model_init\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mmodel init cost: 13.830952167510986\u001b[0m\n",
      "Layout Predict: 100%|███████████████████████████| 10/10 [01:21<00:00,  8.13s/it]\n",
      "MFD Predict: 100%|██████████████████████████████| 10/10 [02:39<00:00, 16.00s/it]\n",
      "MFR Predict: 0it [00:00, ?it/s]\n",
      "Fetching 1 files: 100%|█████████████████████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
      "Fetching 1 files: 100%|█████████████████████████| 1/1 [00:00<00:00, 4809.98it/s]\n",
      "OCR-det ch: 100%|███████████████████████████████| 58/58 [01:09<00:00,  1.20s/it]\n",
      "Table Predict: 0it [00:00, ?it/s]\n",
      "OCR-rec Predict: 100%|████████████████████████| 629/629 [05:05<00:00,  2.06it/s]\n",
      "Processing pages:   0%|                                  | 0/10 [00:00<?, ?it/s]\n",
      "Fetching 2 files:   0%|                                   | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Fetching 2 files: 100%|███████████████████████████| 2/2 [00:00<00:00,  7.65it/s]\u001b[A\n",
      "Processing pages: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "\u001b[32m2025-07-25 09:51:00.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmineru.cli.common\u001b[0m:\u001b[36mdo_parse\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mlocal output dir is /home/luisresende/work/projects/fg-ai/checklist-generation/data/spec-docs/Specifications_small_selected_pages/auto\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U \"mineru[core]\"\n",
    "for i in range(len(files)):\n",
    "\n",
    "    input_path = f'{rules_pdf_folder}/{files[i]}'\n",
    "    output_path = f'{rules_markdown_folder}/markitdown/{files[i].replace(\".pdf\", \".md\")}'\n",
    "    \n",
    "    !mineru -p '{input_path}' -o '{output_path}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c092fb-f615-49cd-af4b-067c146867c6",
   "metadata": {},
   "source": [
    "### Remove output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c73f126a-9475-44d0-a767-3c8ffa86a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/bin/rm -r '{output_folder_path}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
